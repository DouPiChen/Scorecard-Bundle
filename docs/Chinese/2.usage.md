---
sort: 2
---

# 快速入门


- 与Scikit-Learn相似，Scorecard-Bundle有两种class，transformer和predictor，分别遵守fit-transform和fit-predict习惯；
- 完整示例展示[如何训练可解释性和预测力俱佳的评分卡](../examples/%5BExample%5D%20Build%20a%20scorecard%20with%20high%20explainability%20and%20good%20predictability%20with%20Scorecard-Bundle.ipynb)
- 详细用法参见API Guide;

## 模块导入

  ```python
  from scorecardbundle.feature_discretization import ChiMerge as cm
  from scorecardbundle.feature_discretization import FeatureIntervalAdjustment as fia
  from scorecardbundle.feature_encoding import WOE as woe
  from scorecardbundle.feature_selection import FeatureSelection as fs
  from scorecardbundle.model_training import LogisticRegressionScoreCard as lrsc
  from scorecardbundle.model_evaluation import ModelEvaluation as me
  ```

## 特征离散化（基于ChiMerge）

  这里的特征区间均为左开右闭区间。

  ~~~python
  trans_cm = cm.ChiMerge(max_intervals=10, min_intervals=5, output_dataframe=True)
  result_cm = trans_cm.fit_transform(X, y) 
  trans_cm.boundaries_ # 每个特征的区间切分
  ~~~

## 特征编码(WOE)和评估

  ~~~python
  trans_woe = woe.WOE_Encoder(output_dataframe=True)
  result_woe = trans_woe.fit_transform(result_cm, y)
  print(trans_woe.iv_) # 每个特征的信息值 (iv)
  print(trans_woe.result_dict_) # 每个特征的WOE字典和信息值 (iv)
  ~~~

## 特征工程
  
  查看单个特征的取值分布和响应率分布，结合分布在相应领域的可解释性，调整特征的取值分组

### 查看分布和响应率

    ```python
    col = 'housing_median_age'
    fia.plot_event_dist(result_cm[col],y,x_rotation=60)
    ```
<img src="../pics/fe_eg1.PNG">

### 修改特征分组

    ```python
    new_x = cm.assign_interval_str(X[col].values,[33,45]) # apply new interval boundaries to the feature
    woe.woe_vector(new_x, y.values) # check the information value of the resulted feature that applied the new intervals
    ```

    ~~~
    ({'-inf~33.0': -0.21406011499136973,
      '33.0~45.0': 0.08363199161936338,
      '45.0~inf': 0.7012457415969229},
     0.09816803871772663)
    ~~~

### 再次查看分布图

    ~~~python
    fia.plot_event_dist(new_x,y,title=f"Event rate distribution of feature '{col}'", x_label=col,
                        y_label='More valuable than Q90',
                       x_rotation=60,save=True)
    ~~~
    
<img src="../pics/fe_eg2.PNG">
    
### 更新分组特征数据

    ~~~python
    result_cm[col] = new_x # great explainability and predictability. Select.
    feature_list.append(col)
    print(feature_list)
    ~~~

### 完成全部特征的分组检查后，再次将分组特征进行WOE编码

  ~~~python
  trans_woe = woe.WOE_Encoder(output_dataframe=True)
  result_woe = trans_woe.fit_transform(result_cm[feature_list], y) 
  result_woe.head()
  ~~~

  |      | latitude  | median_income | total_rooms | housing_median_age | longitude | population |
  | :--- | :-------- | :------------ | :---------- | :----------------- | :-------- | ---------- |
  | 0    | -0.126659 | -0.295228     | 0.294410    | 0.083632           | -0.37460  | 0.044972   |
  | 1    | 0.300017  | -0.295228     | 0.294410    | -0.214060          | -0.37460  | -0.262287  |
  | 2    | -0.126659 | -1.056799     | -0.236322   | 0.083632           | -0.37460  | -0.262287  |
  | 3    | -0.447097 | -0.295228     | 0.294410    | -0.214060          | 0.68479   | 0.044972   |
  | 4    | 0.300017  | -2.194393     | -0.236322   | 0.083632           | -0.37460  | -0.262287  |

  ~~~python
  trans_woe.iv_ # the information value (iv) for each feature
  ~~~

  ~~~
  {'latitude': 0.09330096146239328,
   'median_income': 2.5275362958451018,
   'total_rooms': 0.12825413939140448,
   'housing_median_age': 0.09816803871772663,
   'longitude': 0.11101533122863683,
   'population': 0.07193530955126093}
  ~~~

## 特征选择

  剔除预测力过低（通常用IV不足0.02筛选）、以及相关性过高引起共线性问题的特征

  (相关性过高的阈值默认为皮尔森相关性系数大于0.6，可通过threshold_corr参数调整)

  ~~~python
  fs.selection_with_iv_corr(trans_woe, result_woe) # corr_with 列示了与该特征相关性过高的特征和相关系数
  ~~~

  |      | factor             | IV       | woe_dict                                          | corr_with                           |
  | :--- | :----------------- | :------- | :------------------------------------------------ | ----------------------------------- |
  | 1    | median_income      | 2.527536 | {'-inf~2.875': -2.1943934506450016, '2.875~3.5... | {}                                  |
  | 2    | total_rooms        | 0.128254 | {'-inf~1176.0': -0.7003111163731507, '1176.0~2... | {'population': -0.708264369318934}  |
  | 4    | longitude          | 0.111015 | {'-118.37~inf': -0.3746002086398019, '-122.41~... | {}                                  |
  | 3    | housing_median_age | 0.098168 | {'-inf~33.0': -0.21406011499136973, '33.0~45.0... | {}                                  |
  | 0    | latitude           | 0.093301 | {'-inf~34.0': -0.12665884912551398, '34.0~37.6... | {}                                  |
  | 5    | population         | 0.071935 | {'-inf~873.0': 0.2876654505272535, '1275.0~152... | {'total_rooms': -0.708264369318934} |

  ~~~python
  # "total_rooms" and "population" are high correlated. Drop "population" since it has lower IV.
  feature_list.remove("population")
  feature_list
  ~~~

  ~~~python
  # Perform WOE encoding again
  trans_woe = woe.WOE_Encoder(output_dataframe=True)
  result_woe = trans_woe.fit_transform(result_cm[feature_list], y) # WOE is fast. This only takes less then 1 seconds
  result_woe.head()
  ~~~

  ~~~python
  # Check correlation heat map
  corr_matrix = result_woe.corr()
  plt.figure(figsize=(3,3))
  sns.heatmap(corr_matrix, cmap = 'bwr', center=0)
  plt.xticks(fontsize=12)
  plt.yticks(fontsize=12)
  plt.show()
  ~~~

<img src="../pics/heatmap.PNG">

## 模型训练

  这里的特征区间（评分规则表的value列）均为左开右闭区间（e.g. 34.0~37.6 代表 (34,  37.6] ）

  ```python
  model = lrsc.LogisticRegressionScoreCard(trans_woe, PDO=-20, basePoints=100, verbose=True)
  model.fit(result_woe, y)
  model.woe_df_ # 从woe_df_属性中可得评分卡规则
  '''
    feature: feature name;
    value: feature intervals that are open to the left and closed to the right;
    woe: the woe encoding for each feature interval;
    beta: the regression coefficients for each feature in the Logistic regression;
    score: the assigned score for each feature interval;
  '''
  ```

  |      | feature            | value                      | woe       | beta     | score |
  | :--- | :----------------- | :------------------------- | :-------- | :------- | :---- |
  | 0    | latitude           | -inf~34.0                  | -0.126659 | 1.443634 | 15.0  |
  | 1    | latitude           | 34.0~37.6                  | 0.300017  | 1.443634 | 32.0  |
  | 2    | latitude           | 37.6~inf                   | -0.447097 | 1.443634 | 1.0   |
  | 3    | median_income      | -inf~2.875                 | -2.194393 | 1.078135 | -48.0 |
  | 4    | median_income      | 2.875~3.5625               | -1.056799 | 1.078135 | -13.0 |
  | 5    | median_income      | 3.5625~3.9625              | -0.681424 | 1.078135 | -1.0  |
  | 6    | median_income      | 3.9625~5.102880000000001   | -0.295228 | 1.078135 | 11.0  |
  | 7    | median_income      | 5.102880000000001~5.765463 | 0.388220  | 1.078135 | 32.0  |
  | 8    | median_income      | 5.765463~6.340365          | 0.909407  | 1.078135 | 48.0  |
  | 9    | median_income      | 6.340365~6.953202          | 1.355401  | 1.078135 | 62.0  |
  | 10   | median_income      | 6.953202~7.737496000000001 | 1.895717  | 1.078135 | 79.0  |
  | 11   | median_income      | 7.737496000000001~8.925106 | 3.130872  | 1.078135 | 117.0 |
  | 12   | median_income      | 8.925106~inf               | 4.940572  | 1.078135 | 173.0 |
  | 13   | total_rooms        | -inf~1176.0                | -0.700311 | 0.792079 | 4.0   |
  | 14   | total_rooms        | 1176.0~2012.0              | -0.236322 | 0.792079 | 14.0  |
  | 15   | total_rooms        | 2012.0~2499.0              | -0.022575 | 0.792079 | 19.0  |
  | 16   | total_rooms        | 2499.0~4178.0              | 0.294410  | 0.792079 | 27.0  |
  | 17   | total_rooms        | 4178.0~inf                 | 0.430445  | 0.792079 | 30.0  |
  | 18   | housing_median_age | -inf~33.0                  | -0.214060 | 2.105821 | 7.0   |
  | 19   | housing_median_age | 33.0~45.0                  | 0.083632  | 2.105821 | 25.0  |
  | 20   | housing_median_age | 45.0~inf                   | 0.701246  | 2.105821 | 62.0  |
  | 21   | longitude          | -118.37~inf                | -0.374600 | 1.451295 | 4.0   |
  | 22   | longitude          | -122.41~-118.37            | 0.152499  | 1.451295 | 26.0  |
  | 23   | longitude          | -inf~-122.41               | 0.684790  | 1.451295 | 48.0  |

## 评分卡调整: 用户可手动调整规则（如下面方法的手动调整、或导出到本地修改好再上传excel文件），并使用predict()的load_scorecard参数传入模型，详见load_scorecard参数的文档。

  ~~~python
  sc_table = model.woe_df_.copy()
  sc_table['score'][(sc_table.feature=='housing_median_age') & (sc_table.value=='45.0~inf')] = 61
  sc_table
  ~~~

## 应用评分卡模型

  ~~~python
  result = model.predict(X[feature_list], load_scorecard=sc_table) # Scorecard should be applied on the original feature values
  result_val = model.predict(X_val[feature_list], load_scorecard=sc_table) # Scorecard should be applied on the original feature values
  result.head() # if model object's verbose parameter is set to False, predict will only return Total scores
  ~~~

  |      | latitude | median_income | total_rooms | housing_median_age | longitude | TotalScore |
  | :--- | :------- | :------------ | :---------- | :----------------- | :-------- | ---------- |
  | 0    | 15.0     | 11.0          | 27.0        | 25.0               | 4.0       | 82.0       |
  | 1    | 32.0     | 11.0          | 27.0        | 7.0                | 4.0       | 81.0       |
  | 2    | 15.0     | -13.0         | 14.0        | 25.0               | 4.0       | 45.0       |
  | 3    | 1.0      | 11.0          | 27.0        | 7.0                | 48.0      | 94.0       |
  | 4    | 32.0     | -48.0         | 14.0        | 25.0               | 4.0       | 27.0       |

  如果是在新的kernal里从本地load模型进行预测：

  ~~~python
  # OR if we load rules from local position.
  sc_table = pd.read_excel('rules')
  
  model = lrsc.LogisticRegressionScoreCard(woe_transformer=None, verbose=True)
  result = model.predict(X[feature_list], load_scorecard=sc_table) # Scorecard should be applied on the original feature values
  result_val = model.predict(X_val[feature_list], load_scorecard=sc_table) # Scorecard should be applied on the original feature values
  result.head() # if model object's verbose parameter is set to False, predict will only return Total scores
  ~~~

## 模型评估（适用于全部二元分类问题）

  ~~~python
  # Train
  evaluation = me.BinaryTargets(y, result['TotalScore'])
  evaluation.plot_all()
  
  # Validation
  evaluation = me.BinaryTargets(y_val, result_val['TotalScore'])
  evaluation.plot_all()
  ~~~

<img src="../pics/eval.PNG">